{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Injest data & Create local DB\n",
    "\n",
    "- This notebook is used to read all the raw data files and combine them all into a nicely formatted sqlite3 database called `docs.db` .\n",
    "- Some manual preprocessing was done on the index files and raw data files inbetween scraping and running this code to make sure they are all consistent.\n",
    "\n",
    "### Notes\n",
    "- The bottom of this notebook contains code for checking how well the merge went (ie. mismatches between index files and actual document files)\n",
    "- After running this notebook I manually moved `docs.db` to the dropbox\n",
    "- TODO: manual correction: move Ed Bastian file into Good lead examples - from nyt and update the index.csv files accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T23:58:38.075053Z",
     "start_time": "2020-12-02T23:58:38.067550Z"
    }
   },
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T23:58:38.883308Z",
     "start_time": "2020-12-02T23:58:38.089685Z"
    }
   },
   "outputs": [],
   "source": [
    "# Jupyter magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T23:58:39.226218Z",
     "start_time": "2020-12-02T23:58:38.885568Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from src import load_txt_files\n",
    "from src import db_funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load docs & Create an index \n",
    "It's going to be a dataframe that stores:\n",
    "- additional information about a document - interviewee, title, source, year, etc. \n",
    "- similarity scores\n",
    "- file paths (temporary link)\n",
    "\n",
    "\n",
    "\n",
    "get index to reflect the order of document, text, token lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T00:24:02.593784Z",
     "start_time": "2020-12-03T00:23:56.927178Z"
    }
   },
   "outputs": [],
   "source": [
    "# grab all the files from these directories and make some tokens\n",
    "input_paths = [\n",
    "        \"./1_data/how_i_built_this/\",\n",
    "#         \"../1_data/example_articles/\",\n",
    "        \"./1_data/NYT_corner_office/\",\n",
    "        \"./1_data/good_lead_articles/\",\n",
    "        \"./1_data/current_transformational_client_articles/\",\n",
    "        \"./1_data/Seeking_Alpha/\",\n",
    "    \n",
    "        ]\n",
    "\n",
    "files, docs, paths = load_txt_files.add_files_from_dir(input_paths)\n",
    "df_index_a = load_txt_files.assemble_index_files(input_paths)\n",
    "df_index_b = pd.DataFrame([files, paths, docs], index=['filename', 'group', 'text']).T\n",
    "\n",
    "\n",
    "a = df_index_a.set_index('filename')\n",
    "b = df_index_b.set_index(\"filename\")\n",
    "\n",
    "df_index = b.join(a, how='left')\n",
    "df_index.shape, df_index_b.shape, df_index_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T00:38:35.639222Z",
     "start_time": "2020-12-03T00:38:35.563976Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_df = df_index.loc[df_index['group'] == \"Seeking_Alpha\"]\n",
    "titles = []\n",
    "for i, row in sub_df.iterrows():\n",
    "    org = row['org']\n",
    "    year = 2020 #row['year']\n",
    "    title = f\"{org} ({year})\"\n",
    "    titles.append(title)\n",
    "\n",
    "df_index.loc[sub_df.index, 'year'] = 2020\n",
    "df_index.loc[sub_df.index, 'title'] = titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save everything to local database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T00:38:53.659859Z",
     "start_time": "2020-12-03T00:38:53.635697Z"
    }
   },
   "outputs": [],
   "source": [
    "# fname = './1_data/Seeking_Alpha/index.csv'\n",
    "\n",
    "# d = pd.read_csv(fname, index_col=0)\n",
    "# d.to_csv('sa_index.csv')\n",
    "# d = d.drop(columns=['Unnamed: 0.1', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1', 'f2'])\n",
    "# d['publication'] = 'earnings call'\n",
    "# d = d.set_index('filename')\n",
    "# d.index = [str(i).split('.txt')[0] for i in d.index]\n",
    "# d.index.name = 'filename'\n",
    "# d.to_csv(fname)\n",
    "# print(len(d))\n",
    "# d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T23:56:19.511909Z",
     "start_time": "2020-12-02T23:56:19.479491Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T00:38:53.867796Z",
     "start_time": "2020-12-03T00:38:53.664109Z"
    }
   },
   "outputs": [],
   "source": [
    "db_filename = 'docs.db'\n",
    "con = db_funcs.create_connection(db_filename)\n",
    "df_index.to_sql('docs', con=con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check overlap between actual files and index.csv contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T00:01:27.235229Z",
     "start_time": "2020-12-03T00:01:27.205306Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(df_index_a), len(df_index_b)\n",
    "# files_not_in_indexed\n",
    "# index_without_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T00:25:04.834594Z",
     "start_time": "2020-12-03T00:25:04.797159Z"
    }
   },
   "outputs": [],
   "source": [
    "files_not_in_indexed = list(set(df_index_b['filename']) - set(df_index_a['filename']))\n",
    "index_without_files = list( set(df_index_a['filename']) - set(df_index_b['filename']))\n",
    "overlap = list( set(df_index_a['filename']) | set(df_index_b['filename']))\n",
    "\n",
    "print(f'{len(files_not_in_indexed)} files not referenced by an index.csv')\n",
    "print(f'{len(index_without_files)} indexes missing a file')\n",
    "print()\n",
    "print(f'{len(overlap)} overlaps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if order accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T00:02:04.487878Z",
     "start_time": "2020-12-03T00:02:04.455400Z"
    }
   },
   "outputs": [],
   "source": [
    "index_order = df_index.index.to_list()\n",
    "file_order = df_index_b['filename'].to_list()\n",
    "for i in range(len(df_index)):\n",
    "    filename1 = index_order[i]\n",
    "    filename2 = file_order[i]\n",
    "    if filename1 != filename2:\n",
    "        print('ERROR', i, filename1, filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T00:02:07.057389Z",
     "start_time": "2020-12-03T00:02:07.020779Z"
    }
   },
   "outputs": [],
   "source": [
    "## random spotcheck to see if name matches article\n",
    "import random\n",
    "\n",
    "def check_doc_index_match():\n",
    "\n",
    "#     d = 'good_lead_articles'\n",
    "#     subsample = df_index[df_index['group'] == d]\n",
    "    subsample = df_index\n",
    "    random_article = random.sample(list(subsample.index), 1)[0]\n",
    "    i = df_index.index.get_loc(random_article)\n",
    "    print(i, random_article)\n",
    "    print(df_index.loc[random_article, 'name'])\n",
    "    print('---')\n",
    "    print(docs[i])\n",
    "    \n",
    "check_doc_index_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:58:49.676052Z",
     "start_time": "2020-11-30T18:58:49.638136Z"
    }
   },
   "outputs": [],
   "source": [
    "# check for duplicate filenames\n",
    "df_index_b[df_index_b['filename'].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:53:29.738095Z",
     "start_time": "2020-11-30T18:53:25.267147Z"
    }
   },
   "source": [
    "# look at order mistmatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:58:50.046516Z",
     "start_time": "2020-11-30T18:58:49.991018Z"
    }
   },
   "outputs": [],
   "source": [
    "missing_index = df_index_b.set_index('filename').loc[files_not_in_indexed].sort_values(by='group')\n",
    "# missing_index[missing_index['dir'] == \"current_transformational_client_articles\"]\n",
    "missing_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:58:50.110064Z",
     "start_time": "2020-11-30T18:58:50.052241Z"
    }
   },
   "outputs": [],
   "source": [
    "df_index_a.set_index('filename').loc[index_without_files]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
