{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape NYT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T19:24:44.132056Z",
     "start_time": "2020-11-17T19:24:44.100732Z"
    }
   },
   "outputs": [],
   "source": [
    "# Jupyter magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T20:18:14.147221Z",
     "start_time": "2020-11-17T20:18:14.092813Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from seleniumrequests import Chrome\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T19:24:46.838229Z",
     "start_time": "2020-11-17T19:24:46.801119Z"
    }
   },
   "outputs": [],
   "source": [
    "save_dir = \"../1_data/NYT_corner_office\"\n",
    "pathlib.Path(save_dir).exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create index of URLs for journal posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T20:44:21.001333Z",
     "start_time": "2020-11-17T20:44:11.955949Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://www.nytimes.com/column/corner-office\"\n",
    "\n",
    "\n",
    "# Change this to where the chromedriver is in your environment\n",
    "path_to_chromedriver = '../chromedriver'\n",
    "\n",
    "driver = Chrome(executable_path=path_to_chromedriver)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T19:26:59.736981Z",
     "start_time": "2020-11-17T19:26:59.667623Z"
    }
   },
   "outputs": [],
   "source": [
    "all_links = []\n",
    "last_article_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T20:01:11.424018Z",
     "start_time": "2020-11-17T20:01:09.375571Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_out_articles(all_links):\n",
    "    section_urls = []\n",
    "    other = []\n",
    "    good_links = []\n",
    "\n",
    "    for l in all_links:\n",
    "        if l is None:\n",
    "            continue\n",
    "        if 'section' in l:\n",
    "            section_urls.append(l)\n",
    "            continue\n",
    "        if 'www.nytimes' not in l:\n",
    "            other.append(l)\n",
    "            continue\n",
    "        if 'subscription' in l:\n",
    "            continue\n",
    "        if 'action=click' in l:\n",
    "            continue\n",
    "        if '/privacy/' in l:\n",
    "            continue\n",
    "        if '/reader-center/' in l:\n",
    "            continue\n",
    "        if '/marketing/' in l:\n",
    "            continue\n",
    "            \n",
    "        n = len(l.split('https://www.nytimes.com/')[-1].split('/'))\n",
    "        if n != 5:\n",
    "#             print(n, l)\n",
    "            continue\n",
    "\n",
    "        else:        \n",
    "            good_links.append(l)\n",
    "            \n",
    "    return good_links\n",
    "\n",
    "\n",
    "els = driver.find_elements_by_tag_name('a')\n",
    "new_links = [l.get_attribute('href') for l in els]\n",
    "all_links += new_links\n",
    "all_links = list(set(all_links))\n",
    "old_count = len(article_links)\n",
    "article_links = filter_out_articles(all_links)\n",
    "new_count = len(article_links)\n",
    "print(f\"{len(new_links)} new links, {len(all_links)} total links, {len(set(article_links))} articles\")\n",
    "\n",
    "if new_count > old_count:\n",
    "    print('Got {new_count - old_count}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T20:00:41.396245Z",
     "start_time": "2020-11-17T20:00:41.360298Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f\"{save_dir}/index.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(article_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T20:00:42.466873Z",
     "start_time": "2020-11-17T20:00:42.427136Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(f\"{save_dir}/index.txt\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T20:00:32.931763Z",
     "start_time": "2020-11-17T20:00:32.870018Z"
    }
   },
   "source": [
    "# Start going through the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T20:02:07.210775Z",
     "start_time": "2020-11-17T20:02:07.163137Z"
    }
   },
   "outputs": [],
   "source": [
    "url = article_links[0]\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T18:18:17.667458Z",
     "start_time": "2020-11-16T18:18:04.637136Z"
    },
    "scrolled": false
   },
   "source": [
    "## Grab the text for each post\n",
    "\n",
    "Some manual fiddling of Selenium required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T20:30:20.596063Z",
     "start_time": "2020-11-17T20:30:20.542003Z"
    }
   },
   "outputs": [],
   "source": [
    "all_titles = []\n",
    "all_text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T20:48:22.715187Z",
     "start_time": "2020-11-17T20:48:22.654722Z"
    }
   },
   "outputs": [],
   "source": [
    "junk = ['ADVERTISEMENT', \"\", 'Offer extended: Subscribe for $1 a week.']\n",
    "def get_article(driver):\n",
    "\n",
    "    title = driver.find_element_by_tag_name('h1').text\n",
    "    text = [e.text for e in driver.find_elements_by_tag_name('p')]\n",
    "    text = [t for t in text if t not in junk]\n",
    "    \n",
    "    for j in junk:\n",
    "        try:\n",
    "            text.remove(j)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return title, text\n",
    "\n",
    "\n",
    "def process_url(driver, url):\n",
    "    # go to article\n",
    "    driver.get(url)\n",
    "    # time.sleep(random.random() * 3)\n",
    "\n",
    "    time.sleep(2 + random.random() * 2)\n",
    "    try:\n",
    "        buttons = driver.find_elements_by_tag_name('button')\n",
    "        for b in buttons:\n",
    "            if \"Show Full Article\" in b.text:\n",
    "                print(b.text)\n",
    "                b.click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    title, text = get_article(driver)\n",
    "    all_titles.append(title)\n",
    "    all_text.append(text)\n",
    "    print(len(text), title)\n",
    "\n",
    "    with open(f\"{save_dir}/{title}.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(text))\n",
    "    return title, text\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T01:01:46.209627Z",
     "start_time": "2020-11-18T01:01:46.156794Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T23:37:58.015499Z",
     "start_time": "2020-11-17T22:58:19.547145Z"
    }
   },
   "outputs": [],
   "source": [
    "start = 102\n",
    "for i, url in enumerate(article_links):\n",
    "    if i < start:\n",
    "        continue\n",
    "    print(i, url)\n",
    "    title, text = process_url(driver, url)\n",
    "    time.sleep(4 + random.random() * 4)\n",
    "    if i % 5 == 0:\n",
    "        time.sleep(30 + random.random() * 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T01:04:30.822012Z",
     "start_time": "2020-11-18T01:04:30.762828Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T01:28:28.626462Z",
     "start_time": "2020-11-18T01:28:28.574423Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "text_bit = []\n",
    "new_text = []\n",
    "for a in all_text:\n",
    "    if len(a) < 9:\n",
    "        continue\n",
    "    b = \"\".join(a[1:10])\n",
    "    if b in text_bit:\n",
    "        continue\n",
    "    text_bit.append(b)\n",
    "    new_text.append(a)\n",
    "len(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T01:22:28.343625Z",
     "start_time": "2020-11-18T01:22:28.252476Z"
    }
   },
   "outputs": [],
   "source": [
    "df_index = pd.DataFrame([all_titles, article_links], index=['title', 'url']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Inensive data munging to pull out names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T17:45:33.902035Z",
     "start_time": "2020-11-18T17:45:33.848335Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parse_setup(setup):\n",
    "\n",
    "#     print('interview with' in setup, setup)\n",
    "    if 'interview with' in setup:\n",
    "        name = setup.split('This interview with')[1].split(',')[0]\n",
    "#     elif 'interview of' in setup:\n",
    "#         name = setup.split('This interview of')[1].split(',')[0]\n",
    "    job_title = setup.split(',')[1]\n",
    "    return name, job_title\n",
    "\n",
    "def find_setup(txt):\n",
    "    setup = \"\"\n",
    "    for t in txt:\n",
    "        if \"This interview with\" in t:\n",
    "            return t\n",
    "#         if \"This interview of\" in t:\n",
    "#             return t\n",
    "\n",
    "alternate_txt = [] \n",
    "alternate_titles = []\n",
    "data = []\n",
    "for title, txt, url in zip(all_titles, new_text, article_links):\n",
    "    \n",
    "    \n",
    "    name, job_title = \"na\", \"\"\n",
    "    setup = find_setup(txt)\n",
    "    if setup is not None:\n",
    "        try:\n",
    "            name, job_title = parse_setup(setup)\n",
    "        except:\n",
    "            print('WARNING')\n",
    "            print(setup)\n",
    "    else:\n",
    "        alternate_txt.append(txt)\n",
    "        alternate_titles.append(title)\n",
    "    fname = 'check'\n",
    "    \n",
    "    d = {\n",
    "        'title': title,\n",
    "        'url': url,\n",
    "        'year':year,\n",
    "        'filename': fname,\n",
    "        'name': name,\n",
    "        'job_title': job_title,\n",
    "    }\n",
    "    data.append(d)\n",
    "#     print(txt[:3])\n",
    "#     print(url)\n",
    "#     year = url.split('.com/')[1].split('/')[0]\n",
    "#     print(f'{year}----------{setup_found}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T17:45:34.955714Z",
     "start_time": "2020-11-18T17:45:34.920014Z"
    }
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(data)\n",
    "len(d[d['name'] == 'na'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T18:18:16.153940Z",
     "start_time": "2020-11-18T18:18:16.084997Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n =['Arne Sorenson', 'Michael Evans', 'Keith Mestrich', \n",
    "    'Paul Polman', 'Jeff Raider', 'multiple', 'Bernardo Hees', 'Jo Ann Jenkins', \n",
    "    \"Stacy Brown-Philpot\",\n",
    "   'Claire Babineaux-Fontenot',\n",
    "    'Maigread Eichten',\n",
    "    'Matt Mullenweg',\n",
    "    'Chuck Robbins',\n",
    "    'Indra Nooyi',\n",
    "   'Sara Horowitz', #just lastname find\n",
    "   'Sundar Pichai',\n",
    "    'Steven Corwin',\n",
    "    'Marc Benioff',\n",
    "    'Lonnie Bunch',\n",
    "    'Katrina Lake',\n",
    "    'Julie Sweet',\n",
    "    'Mellody Hobson',\n",
    "    'Adena Friedman',\n",
    "    'Gail McGovern',\n",
    "    'Thasunda Brown Duckett',\n",
    "    'Stephen Ross',\n",
    "    'John Donahoe',\n",
    "    'James Dyson',\n",
    "    'Hadi Partovi',\n",
    "    'Larry Praeger',\n",
    "    'Eileen Fisher',\n",
    "    'Richard Anderson',\n",
    "    'Al Kelly',\n",
    "    'Guy Kawasaki',\n",
    "    'Ken Frazier',\n",
    "    'Alexis Ohanian',\n",
    "    'Michael Mathieu',\n",
    "    'Emily Powell',\n",
    "    'Doug Parker',\n",
    "    'Michael Dell',\n",
    "    'Joey Bergstein',\n",
    "    'Michele Roberts',\n",
    "    'Rebecca Lynn',\n",
    "    'Mark Hoplamazian',\n",
    "    'Julia Hartz',\n",
    "    'Ajay Banga',\n",
    "    'Marissa Mayer',\n",
    "    'Dan Rosensweig',\n",
    "    'Chris Paul',\n",
    "    'Vas Narasimhan',\n",
    "    'Darren Walker',\n",
    "    'Patricia de Stacy Harrison',\n",
    "    'Niki Leondakis',\n",
    "    'Mark Bertolini',\n",
    "    'Mary Kay Henry',\n",
    "    'Gwyneth Paltrow',\n",
    "    'Payal Kadakia',\n",
    "    'Eduardo Castro-Wright',\n",
    "    'Daniel P. Amos',\n",
    "    'Jane Goodall',\n",
    "    'Leana Wen',\n",
    "    'John Chambers',\n",
    "    'Sarah Friar',\n",
    "    'Jacqueline Kosecoff',\n",
    "    'Laurene Powell Jobs',\n",
    "    'Gregg Renfrew',\n",
    "    'Adam Bryant',\n",
    "    'Hamdi Ulukaya',\n",
    "    'Roland Swenson',\n",
    "    'Linda Findley Kozlowski',\n",
    "    'Tristan Walker',\n",
    "    'Dan Schulman',\n",
    "    'Will Wright',\n",
    "    'Michele Buck',\n",
    "    'Clarence Otis Jr.',\n",
    "    'Richard Branson and Holly Branson',\n",
    "    'Susan Lyne',\n",
    "    'Reid Hoffman',\n",
    "    'David Miliband',\n",
    "    'Steven Ballmer',\n",
    "    'Steve Mollenkopf',\n",
    "    'John Mackey',\n",
    "    'Paula Schneider',\n",
    "    'David Rubenstein',\n",
    "    'Dany Levy',\n",
    "    'Lynn Jurich',\n",
    "    'Maverick Carter'\n",
    "   ]\n",
    "\n",
    "# count = 0\n",
    "# for i, (title, txt) in enumerate(zip(alternate_titles, alternate_txt)):\n",
    "#     print('----')\n",
    "\n",
    "#     if i < len(n):\n",
    "#         print(n[i])\n",
    "# #         continue\n",
    "\n",
    "#     print(txt[:3])\n",
    "#     for t in txt:\n",
    "#         if 'interview' in t:\n",
    "#             print(t)\n",
    "#             break\n",
    "#         if 'chief' in t:\n",
    "#             print(t)\n",
    "#             break\n",
    "#         if 'grew up' in t:\n",
    "#             print(t)\n",
    "#             break\n",
    "#     else:\n",
    "#         print(txt[:3])\n",
    "            \n",
    "#     print(title)\n",
    "#     count += 1\n",
    "    \n",
    "\n",
    "len(d[d['name'] == 'na']), len(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T18:18:43.724081Z",
     "start_time": "2020-11-18T18:18:43.660412Z"
    }
   },
   "outputs": [],
   "source": [
    "# d.loc[d['name'] == '', 'name'] = 'John Chambers'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T18:26:22.436735Z",
     "start_time": "2020-11-18T18:26:22.334427Z"
    }
   },
   "outputs": [],
   "source": [
    "fnames = []\n",
    "for i, row in d.iterrows():\n",
    "    n = row['name']\n",
    "    last_name = n.split()[-1]\n",
    "#     print(n, '-', last_name)\n",
    "    fname = f\"{last_name.lower()}_nyt_{year}\"\n",
    "    fnames.append(fname)\n",
    "\n",
    "d['filename'] = fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T18:26:54.712052Z",
     "start_time": "2020-11-18T18:26:54.642231Z"
    }
   },
   "outputs": [],
   "source": [
    "d.to_csv(f\"{save_dir}/index.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T18:34:59.813882Z",
     "start_time": "2020-11-18T18:34:59.560000Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, row in d.iterrows():\n",
    "    txt = [t for t in new_text[i] if t not in ['CORNER OFFICE', \"\", \"by Adam Bryant\"]]\n",
    "    with open(f\"{save_dir}/{row['filename']}.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T18:32:50.137248Z",
     "start_time": "2020-11-18T18:32:50.085286Z"
    }
   },
   "outputs": [],
   "source": [
    "row['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T18:37:42.491444Z",
     "start_time": "2020-11-18T18:37:42.440530Z"
    }
   },
   "outputs": [],
   "source": [
    "# pd.read_csv(f\"{save_dir}/index.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
